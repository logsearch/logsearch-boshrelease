---
name: archiver
packages:
- logstash
- java8
templates:
  bin/logstash.process.erb: bin/logstash.process
  bin/s3upload.cron.erb: bin/s3upload.cron
  bin/scpupload.cron.erb: bin/scpupload.cron
  config/logstash.conf.erb: config/logstash.conf
  logsearch/metric-collector/files/collector: logsearch/metric-collector/files/collector
  config/scpupload.pem.erb: config/scpupload.pem
properties:
  redis.host:
    description: Redis host of queue
  redis.port:
    description: Redis port of queue
    default: 6379
  redis.key:
    description: Name of queue to pull messages from
    default: logstash

  archiver.method:
    description: "Select the method for archiving"
    default: "s3"

  archiver.s3.bucket:
    description: "S3 Bucket"
    default: ""
  archiver.s3.prefix:
    description: "S3 Prefix"
    default: ""
  archiver.s3.endpoint:
    description: "S3 Endpoint"
    default: "s3.amazonaws.com"
  archiver.s3.access_key_id:
    description: "S3 Access Key ID"
    default: ""
  archiver.s3.secret_access_key:
    description: "S3 Secret Access Key"
    default: ""

  archiver.scp.host:
    description: "Host to transfer the log files to"
    default: ""
  archiver.scp.port:
    description: "Port of the remote host"
    default: 22
  archiver.scp.username:
    description: "If your remote username differs from the default root one"
    default: root
  archiver.scp.ssh_key:
    description: "Private ssh key in PEM format (file contents, not a path)"
    default: ""
  archiver.scp.destination:
    description: "Destination directory for the tranferred log files"
    default: ""

  archiver.data_dir:
    default: "/var/vcap/store/archiver"
    description: "Directory for dumping log files"
  archiver.cron_schedule:
    default: "*/30 * * * *"
    description: "Schedule for pausing the archiver to upload log files"
  archiver.workers:
    default: "auto"
    description: "The number of worker threads that logstash should use (default: auto = one per CPU)"
