# this is auto-generated from
# https://github.com/logsearch/logsearch-filters-common
# 703f23d4ef3532ef01cc0a07361efd131418b25d

if [@type] in ["syslog", "relp"] {
  # syslog/relp
  
  grok {
      match => { "@message" => "(?:%{INT:syslog6587_msglen} )?<%{POSINT:syslog_pri}>(?:%{NONNEGINT:syslog5424_ver} )?(?:%{SYSLOGTIMESTAMP:syslog_timestamp}|%{TIMESTAMP_ISO8601:syslog_timestamp}) %{SYSLOGHOST:syslog_hostname} %{DATA:syslog_program}(?:\[%{POSINT:syslog_pid}\])?(:)? %{GREEDYDATA:syslog_message}" }
      add_field => [ "received_at", "%{@timestamp}" ]
      add_field => [ "received_from", "%{host}" ]
      add_tag => [ "syslog_standard" ]
      tag_on_failure => ["_grokparsefailure-syslog_standard"]
  }
  
  if !("_grokparsefailure-syslog_standard" in [tags]) {
      syslog_pri { }
  
      date {
          match => [ "syslog_timestamp", "MMM  d HH:mm:ss", "MMM dd HH:mm:ss", "ISO8601" ]
          timezone => "UTC"
      }
  
      # hostname: handle syslog configurations where hostname is localhost
      if ([syslog_hostname] == "localhost" ) {
          grok {
              match => { "received_from" => "%{IPORHOST:syslog_hostname}(?::%{POSINT:syslog_port})?" }
              overwrite => [ "syslog_hostname", "syslog_port" ]
              tag_on_failure => [ "_grokparsefailure-syslog_standard-hostname"]
          }
      }
  
      mutate {
          replace => [ "@source.host", "%{syslog_hostname}" ]
      }
  
      mutate {
          convert => [ "syslog5424_ver", "integer" ]
          convert => [ "syslog6587_msglen", "integer" ]
          remove_field => [
              #"syslog_pri",
              "syslog_hostname",
              "syslog_port",
              "syslog_timestamp"
          ]
      }
  }

}

if [@type] == "syslog" and [syslog_message] =~ /^\- \- \[NXLOG/ {
  grok {
      match => [ "syslog_message", "\- \- \[NXLOG@14506 (?<shipper[source_params]>[^\]]+)\] %{GREEDYDATA:@message}" ]
      overwrite => [
          "@message"
      ]
      tag_on_failure => [ "_grokparsefailure-nxlog_standard" ]
  }
  
  if "_grokparsefailure-nxlog_standard" not in [tags] {
      # grok doesn't like @named groups
      mutate {
          rename => [ "shipper", "@shipper" ]
      }
  
      kv {
        source => "@shipper[source_params]"
        target => "@source"
      }
  
      mutate {
          # syslog is just the transport; no need to store
          remove_field => "syslog_message"
          remove_field => "syslog_pri"
          remove_field => "syslog5424_ver"
          remove_field => "syslog_program"
          remove_field => "syslog_severity_code"
          remove_field => "syslog_facility_code"
          remove_field => "syslog_facility"
          remove_field => "syslog_severity"
  
          # syslog host is actually the shipper
          rename => [ "@source.host", "@shipper[host]" ]
  
          # these arbitrary parameters are parsed to @source
          remove_field => "@shipper[source_params]"
  
          # these are parsed with kv, but they're static nxlog shipper properties
          rename => [ "@source[EventReceivedTime]", "@shipper[event_received_time" ]
          rename => [ "@source[SourceModuleName]", "@shipper[module_name" ]
          rename => [ "@source[SourceModuleType]", "@shipper[module_type" ]
  
          # @source[type] should replace the syslog @type
          rename => [ "@source[type]", "@type" ]
      }
  }

}

if [@type] == "json" {
  json {
    source => "@message"
  }
  
  date {
    match => [ "timestamp", "ISO8601" ]
    timezone => "UTC"
  }
  
  
  #
  # typically message will be a string, so message_data is used as the object
  #
  
  ruby {
    code => "event['message_data'] = event.remove('message') if event.include?('message') and event['message'].is_a? Hash"
  }
  
  if [@timestamp] {
    #
    # We ran into a situation where a shipper was sending an improperly formatted
    # message into the logsearch cluster. It included a raw @timestamp field, but
    # it was an array. This causes the logstash parsing process to completely block
    # because it is unable to convert event['@timestamp'] since it expects a Time.
    #
    # This performs a check to ensure @timestamp is a Time, otherwise it renames
    # the field to _timestamperror, adds a _timestamperror tag, and replaces
    # @timestamp with the current time.
    #
  
    ruby {
      code => "if Time != event['@timestamp'].class ; event.tag('_timestamperror') ; event['_timestamperror'] = event['@timestamp'] ; event['@timestamp'] = Time.new ; end"
    }
  }

}

if [@type] == "elasticsearch_request" {
  json {
    source => "@message"
  }
  
  mutate {
    remove_field => [ 'day', 'dow', 'hour', 'minute', 'month', 'year' ]
  }
  
  date {
    match => [ "starttime", "ISO8601" ]
    timezone => "UTC"
  }

}

if [@type] == "nginx_combined" {
  grok {
    match => [ "@message", "%{IPORHOST:remote_addr} - (?:%{USER:remote_user}|-) \[%{HTTPDATE:time_local}\] \"(?:%{WORD:request_method} %{URIPATHPARAM:request_uri}(?: HTTP/%{NUMBER:request_httpversion})?|-)\" %{INT:status} (?:%{NONNEGINT:body_bytes_sent}|-) \"(?:%{URI:http_referer}|-)\" %{QS:http_user_agent} (?:%{NONNEGINT:request_time}|-)" ]
    match => [ "@message", "%{IPORHOST:remote_addr} - (?:%{USER:remote_user}|-) \[%{HTTPDATE:time_local}\] \"(?:%{WORD:request_method} %{URIPATHPARAM:request_uri}(?: HTTP/%{NUMBER:request_httpversion})?|-)\" %{INT:status} (?:%{NONNEGINT:body_bytes_sent}|-) \"(?:%{URI:http_referer}|-)\" %{QS:http_user_agent}" ]
    add_tag => "nginx"
    tag_on_failure => [ "_grokparsefailure-nginx_combined" ]
  }
  
  date {
    match => [ "time_local", "dd/MMM/YYYY:HH:mm:ss Z" ]
    timezone => "UTC"
  }

}